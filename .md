# Lateral Project Documentation

## Project Overview

The Lateral Project is a lane detection and 3D object recognition system based on Lateral-SOTA. It combines 2D lane detection using Ultra-Fast Lane Detection with 3D point cloud processing using RANSAC plane fitting. The system processes KITTI dataset images and LiDAR point clouds to detect lanes, match them with 3D points, and calculate lateral distances to objects.

**Key Features:**
- 2D lane detection using deep learning (Ultra-Fast Lane Detection)
- 3D point cloud processing with RANSAC plane segmentation
- LiDAR-to-camera projection for lane matching
- Lateral distance calculation from objects to lanes
- ROS visualization support for real-time applications

---

## Directory Structure

```
Lateral/
|-- .gitignore                    # Git ignore patterns
|-- README.md                     # Project README
|-- requirements.txt              # Python dependencies
|-- setup.py                      # Package installation script
|
|-- configs/
|   |-- default.yaml              # Default configuration file
|
|-- notebooks/
|   |-- exploration.ipynb         # Jupyter notebook for exploration
|
|-- scripts/
|   |-- download_weights.py       # Script to download pretrained weights
|   |-- setup_dataset.py          # Script to setup KITTI dataset
|
|-- src/
|   |-- __init__.py               # src package initialization
|   |-- .md                       # This documentation file
|   |
|   |-- lateral_sota/             # Main pipeline package
|   |   |-- __init__.py
|   |   |-- README.md             # Package README
|   |   |-- 1_Lane_2D.py          # Step 1: 2D lane detection
|   |   |-- 2_curveRansac_Matching.py  # Step 2a: Curved road RANSAC matching
|   |   |-- 2_lineRansac_Matching.py   # Step 2b: Straight road RANSAC matching
|   |   |-- 3_Marking.py          # Step 3: Lane marking and distance calculation
|   |   |-- 4_Evaluation.py       # Step 4: Evaluation metrics
|   |   |-- ransacPlaneobject.py  # RANSAC plane segmentation utility
|   |   |-- label_plotting.py     # ROS visualization utilities
|   |   |-- Point_Visualizer.cpp  # C++ point cloud visualizer
|   |   |-- 000_Distance_Calculation_Notebook.ipynb  # Distance calculation notebook
|   |   |
|   |   |-- ultrafastLaneDetector/  # Lane detection submodule
|   |       |-- __init__.py       # Package exports
|   |       |-- backbone.py       # Neural network backbones (ResNet, VGG)
|   |       |-- model.py          # Lane detection model architecture
|   |       |-- ultrafastLaneDetector.py  # Main detector class
|   |
|   |-- my_modules/               # Custom modules
|       |-- __init__.py           # Package initialization
|       |-- custom_pipeline.py    # Enhanced pipeline wrapper
|
|-- tests/
|   |-- __init__.py
|   |-- test_pipeline.py          # Unit tests
|
|-- weights/
    |-- lane_detection/
    |   |-- .gitkeep
    |   |-- tusimple_res18.pth    # TUSIMPLE pretrained weights
    |-- 3d_detection/
        |-- pv_rcnn_kitti.pth     # PV-RCNN 3D detection weights
```

---

## Pipeline Architecture

### Execution Flow

The pipeline consists of 4 main stages executed sequentially:

```mermaid
flowchart TD
    A[Input Image] --> B[1_Lane_2D.py]
    B --> C[Lane Detection CSV]
    C --> D{Road Type?}
    D -->|Curved| E[2_curveRansac_Matching.py]
    D -->|Straight| F[2_lineRansac_Matching.py]
    E --> G[3D Lane Points]
    F --> G
    G --> H[3_Marking.py]
    H --> I[Distance Calculation]
    I --> J[4_Evaluation.py]
    J --> K[Evaluation Results]
    
    L[LiDAR Point Cloud] --> E
    L --> F
    M[Calibration Data] --> E
    M --> F
    N[Object Labels] --> H
    N --> J
```

### Stage Descriptions

| Stage | File | Purpose | Input | Output |
|-------|------|---------|-------|--------|
| 1 | [`1_Lane_2D.py`](lateral_sota/1_Lane_2D.py) | 2D lane detection | RGB image | Lane coordinates CSV |
| 2a | [`2_curveRansac_Matching.py`](lateral_sota/2_curveRansac_Matching.py) | Curved road matching | Lane CSV, LiDAR, calib | 3D lane points, RANSAC fit |
| 2b | [`2_lineRansac_Matching.py`](lateral_sota/2_lineRansac_Matching.py) | Straight road matching | Lane CSV, LiDAR, calib | 3D lane points, RANSAC fit |
| 3 | [`3_Marking.py`](lateral_sota/3_Marking.py) | Distance calculation | 3D lanes, objects | Lateral distances |
| 4 | [`4_Evaluation.py`](lateral_sota/4_Evaluation.py) | Evaluation | Predictions, ground truth | Evaluation metrics |

---

## Module Documentation

### 1. Lane Detection - [`1_Lane_2D.py`](lateral_sota/1_Lane_2D.py)

**Purpose:** Entry point for 2D lane detection. Processes RGB images to detect lane markings using the Ultra-Fast Lane Detection model.

**Imports:**
```python
import cv2
import sys
from ultrafastLaneDetector import UltrafastLaneDetector, ModelType
```

**Functions:** None (script-style execution)

**Execution Flow:**
1. Accepts command-line argument for image sequence number
2. Initializes [`UltrafastLaneDetector`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py) with TUSIMPLE model
3. Reads RGB image from dataset
4. Calls [`detect_lanes()`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:108) method
5. Writes lane coordinates to CSV file
6. Displays detected lanes on image

**Input Data:**
- Image path: `../../../../dataset/training/image_2/{name}.png`
- Model path: `../models/tusimple_18.pth`
- CSV output: `../../CSV_Communication/1_lane.csv`

**Output Data:**
- CSV file containing:
  - Line 0: Left lane polynomial coefficients
  - Line 1: Right lane polynomial coefficients
  - Line 2: Left lane X coordinates
  - Line 3: Left lane Y coordinates
  - Line 4: Right lane X coordinates
  - Line 5: Right lane Y coordinates

---

### 2. Curve RANSAC Matching - [`2_curveRansac_Matching.py`](lateral_sota/2_curveRansac_Matching.py)

**Purpose:** Matches 2D lane detections with 3D LiDAR points for curved roads using quadratic RANSAC regression.

**Imports:**
```python
import sys
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import csv
from ransacPlaneobject import ransacPlaneobject
import math
from sklearn import linear_model, datasets
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import RANSACRegressor
```

**Classes:**

#### [`PolynomialRegression`](lateral_sota/2_curveRansac_Matching.py:12)

Custom polynomial regression estimator for use with scikit-learn RANSAC.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, degree=2, coeffs=None)` | Initialize with polynomial degree |
| `fit` | `fit(self, X, y)` | Fit polynomial to data using `np.polyfit` |
| `get_params` | `get_params(self, deep=False)` | Return parameters dict |
| `set_params` | `set_params(self, coeffs=None, random_state=None)` | Set coefficients |
| `predict` | `predict(self, X)` | Predict using polynomial equation |
| `score` | `score(self, X, y)` | Calculate mean squared error |

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`ransac_plot()`](lateral_sota/2_curveRansac_Matching.py:34) | `ransac_plot(xArray, yArray, y_hat, inlier_mask)` | Visualize RANSAC results |
| [`rgb2gray()`](lateral_sota/2_curveRansac_Matching.py:44) | `rgb2gray(rgb)` | Convert RGB to grayscale |

**Execution Flow:**
1. Load lane coordinates from CSV (from Step 1)
2. Call [`ransacPlaneobject()`](lateral_sota/ransacPlaneobject.py:17) to segment ground plane
3. Load calibration matrices (P2, R0_rect, Tr_velo_to_cam)
4. Project LiDAR points to 2D image coordinates
5. Match projected points with lane pixels
6. Filter points by intensity threshold
7. Apply quadratic RANSAC regression
8. Save matched 3D lane points to text files

**Input Data:**
- Lane CSV: `../../CSV_Communication/1_lane.csv`
- Image: `../../../../dataset/training/image_2/{name}.png`
- LiDAR: `../../../../dataset/training/velodyne/{name}.pcd`
- Calibration: `../../../../dataset/training/calib/{name}.txt`

**Output Data:**
- Left lane 3D: `../../CSV_Communication/2_matched_left.txt`
- Right lane 3D: `../../CSV_Communication/2_matched_right.txt`
- Projected visualization: `../../../../dataset/projected_output/{name}.png`

---

### 3. Line RANSAC Matching - [`2_lineRansac_Matching.py`](lateral_sota/2_lineRansac_Matching.py)

**Purpose:** Matches 2D lane detections with 3D LiDAR points for straight roads using linear RANSAC regression.

**Imports:**
```python
import sys
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import csv
from ransacPlaneobject import ransacPlaneobject
import math
from sklearn import linear_model, datasets
```

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`ransacPlot()`](lateral_sota/2_lineRansac_Matching.py:11) | `ransacPlot(xArray, yArray, side, maximum_distance=50)` | RANSAC visualization and file output |

**Execution Flow:**
1. Same initial steps as curve RANSAC
2. Uses linear RANSAC instead of quadratic
3. Outputs lane equations to text files

**Output Data:**
- Left lane RANSAC: `../../CSV_Communication/left_lane_Ransac.txt`
- Right lane RANSAC: `../../CSV_Communication/right_lane_Ransac.txt`

---

### 4. Marking - [`3_Marking.py`](lateral_sota/3_Marking.py)

**Purpose:** Calculates lateral distances from detected objects to lane boundaries. Publishes visualization markers to ROS.

**Imports:**
```python
import rospy
import math
import torch, os, cv2
import numpy as np
from std_msgs.msg import String
from geometry_msgs.msg import PointStamped
from visualization_msgs.msg import Marker, MarkerArray
import shapely.geometry as geom
from shapely.geometry import Point
import matplotlib.pyplot as plt
from std_msgs.msg import ColorRGBA
import sys
```

**Classes:**

#### [`NearestPoint`](lateral_sota/3_Marking.py:18)

Calculates nearest point on lane line to objects.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, left_line, right_line, ax)` | Initialize with lane geometries |
| `__call__` | `__call__(self, xy_point, side, point_on_lane, sign, direction)` | Calculate distance to lane |
| `draw_segment` | `draw_segment(self, object_list)` | Draw distance lines and return results |

#### [`Point_Coordinate`](lateral_sota/3_Marking.py:105)

Simple coordinate container class.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, x, y, z)` | Store 3D coordinates |

#### [`Lanelabel`](lateral_sota/3_Marking.py:111)

Lane label container class.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, l_x, l_y, l_z, r_x, r_y, r_z)` | Store left/right lane points |
| `__repr__` | `__repr__(self)` | String representation |

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`cls_type_to_id()`](lateral_sota/3_Marking.py:99) | `cls_type_to_id(cls_type)` | Convert class name to ID |

**ROS Publishers:**
- `plotting`: PointStamped messages
- `left_eq`: Marker for left lane
- `right_eq`: Marker for right lane
- `answer`: Marker for distance lines
- `text`: MarkerArray for distance labels

**Input Data:**
- Left lane: `../../CSV_Communication/left_lane_Ransac.txt`
- Right lane: `../../CSV_Communication/right_lane_Ransac.txt`
- Labels: `../../../../dataset/training/label_2/{name}.txt`

---

### 5. Evaluation - [`4_Evaluation.py`](lateral_sota/4_Evaluation.py)

**Purpose:** Evaluates lateral distance predictions against ground truth labels.

**Imports:**
```python
import rospy
import math
import torch, os, cv2
import numpy as np
from std_msgs.msg import String
from geometry_msgs.msg import PointStamped
from visualization_msgs.msg import Marker
import shapely.geometry as geom
from shapely.geometry import Point
import matplotlib.pyplot as plt
from std_msgs.msg import ColorRGBA
import sys
import csv
```

**Classes:**

Same classes as [`3_Marking.py`](lateral_sota/3_Marking.py):
- [`NearestPoint`](lateral_sota/4_Evaluation.py:22)
- [`Point_Coordinate`](lateral_sota/4_Evaluation.py:111)
- [`Lanelabel`](lateral_sota/4_Evaluation.py:117)

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`cls_type_to_id()`](lateral_sota/4_Evaluation.py:105) | `cls_type_to_id(cls_type)` | Convert class name to ID |

**Input Data:**
- Labels: `../../../../labeled_txt/{name}.txt`
- Lane files: Same as marking module

**Output Data:**
- Evaluation file: `../../CSV_Communication/evaluation.txt`

---

### 6. RANSAC Plane Object - [`ransacPlaneobject.py`](lateral_sota/ransacPlaneobject.py)

**Purpose:** Segments LiDAR point cloud into ground plane and objects using RANSAC.

**Imports:**
```python
from sensor_msgs.msg import PointCloud2
import sensor_msgs.point_cloud2 as pc2
import pcl
import sys
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
import csv
```

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`ransacPlaneobject()`](lateral_sota/ransacPlaneobject.py:17) | `ransacPlaneobject(pointcloudPath)` | Segment point cloud into plane and objects |

**Returns:**
- `inliers`: numpy array of ground plane points (x, y, z, intensity)
- `outliers`: numpy array of object points (x, y, z, intensity)

**RANSAC Parameters:**
- Model type: `pcl.SACMODEL_NORMAL_PLANE`
- Method: `pcl.SAC_RANSAC`
- Max iterations: 100
- Distance threshold: 0.3

---

### 7. Label Plotting - [`label_plotting.py`](lateral_sota/label_plotting.py)

**Purpose:** ROS visualization utility for plotting lane labels in RViz.

**Imports:**
```python
import rospy
import math
import torch, os, cv2
import numpy as np
from std_msgs.msg import String
from geometry_msgs.msg import PointStamped
from visualization_msgs.msg import Marker
```

**Classes:**

#### [`Point()`](lateral_sota/label_plotting.py:15)

Simple 3D point class.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, x, y, z)` | Initialize 3D coordinates |

#### [`Lanelabel()`](lateral_sota/label_plotting.py:21)

Lane label container.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, l_x, l_y, l_z, r_x, r_y, r_z)` | Store lane points |
| `__repr__` | `__repr__(self)` | String representation |

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`cls_type_to_id()`](lateral_sota/label_plotting.py:9) | `cls_type_to_id(cls_type)` | Convert class name to ID |

**ROS Publishers:**
- `plotting`: PointStamped messages
- `robotMarker`: Marker for visualization

---

### 8. UltrafastLaneDetector Package

#### [`__init__.py`](lateral_sota/ultrafastLaneDetector/__init__.py)

**Exports:**
```python
from ultrafastLaneDetector.ultrafastLaneDetector import UltrafastLaneDetector, ModelType
```

---

#### [`backbone.py`](lateral_sota/ultrafastLaneDetector/backbone.py)

**Purpose:** Neural network backbone architectures for lane detection.

**Imports:**
```python
import torch, pdb
import torchvision
import torch.nn.modules
```

**Classes:**

#### [`vgg16bn`](lateral_sota/ultrafastLaneDetector/backbone.py:5)

VGG16 with Batch Normalization backbone.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, pretrained=False)` | Load VGG16-BN from torchvision |
| `forward` | `forward(self, x)` | Forward pass |

#### [`resnet`](lateral_sota/ultrafastLaneDetector/backbone.py:14)

ResNet backbone supporting multiple variants.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, layers, pretrained=False)` | Initialize ResNet variant |
| `forward` | `forward(self, x)` | Forward pass returning multi-scale features |

**Supported ResNet Variants:**
- `18`: ResNet-18
- `34`: ResNet-34
- `50`: ResNet-50
- `101`: ResNet-101
- `152`: ResNet-152
- `50next`: ResNeXt-50
- `101next`: ResNeXt-101
- `50wide`: Wide ResNet-50
- `101wide`: Wide ResNet-101

**Forward Pass Returns:**
- `x2`: Feature map from layer2
- `x3`: Feature map from layer3
- `x4`: Feature map from layer4

---

#### [`model.py`](lateral_sota/ultrafastLaneDetector/model.py)

**Purpose:** Lane detection model architecture.

**Imports:**
```python
import torch
from ultrafastLaneDetector.backbone import resnet
import numpy as np
```

**Classes:**

#### [`conv_bn_relu`](lateral_sota/ultrafastLaneDetector/model.py:5)

Convolution-BatchNorm-ReLU block.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, bias=False)` | Initialize conv block |
| `forward` | `forward(self, x)` | Forward pass |

#### [`parsingNet`](lateral_sota/ultrafastLaneDetector/model.py:18)

Main lane detection network.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, size=(288, 800), pretrained=True, backbone='50', cls_dim=(37, 10, 4), use_aux=False)` | Initialize network |
| `forward` | `forward(self, x)` | Forward pass returning lane predictions |

**Constructor Parameters:**
| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `size` | tuple | (288, 800) | Input image size (H, W) |
| `pretrained` | bool | True | Use pretrained backbone |
| `backbone` | str | '50' | ResNet variant |
| `cls_dim` | tuple | (37, 10, 4) | (griding_num, cls_num_per_lane, num_lanes) |
| `use_aux` | bool | False | Use auxiliary segmentation head |

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`initialize_weights()`](lateral_sota/ultrafastLaneDetector/model.py:98) | `initialize_weights(*models)` | Initialize weights for models |
| [`real_init_weights()`](lateral_sota/ultrafastLaneDetector/model.py:101) | `real_init_weights(m)` | Recursive weight initialization |

---

#### [`ultrafastLaneDetector.py`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py)

**Purpose:** Main lane detector class with inference and visualization.

**Imports:**
```python
import cv2
import torch
import scipy.special
import numpy as np
import torchvision
import torchvision.transforms as transforms
from PIL import Image
from enum import Enum
from scipy.spatial.distance import cdist
import csv
import math
from ultrafastLaneDetector.model import parsingNet
```

**Constants:**
```python
lane_colors = [(0,0,255), (0,255,0), (255,0,0), (0,255,255)]
tusimple_row_anchor = [64, 68, 72, ..., 284]  # 56 row anchors
culane_row_anchor = [121, 131, ..., 287]  # 18 row anchors
```

**Classes:**

#### [`ModelType`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:24) (Enum)

| Value | Description |
|-------|-------------|
| `TUSIMPLE` | TUSIMPLE dataset model |
| `CULANE` | CULane dataset model |

#### [`ModelConfig`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:28)

Configuration container for different model types.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, model_type)` | Initialize config based on model type |
| `init_tusimple_config` | `init_tusimple_config(self)` | Set TUSIMPLE parameters |
| `init_culane_config` | `init_culane_config(self)` | Set CULane parameters |

**Configuration Parameters:**
| Parameter | TUSIMPLE | CULane |
|-----------|----------|--------|
| `img_w` | 1242 | 1640 |
| `img_h` | 375 | 590 |
| `row_anchor` | 56 values | 18 values |
| `griding_num` | 100 | 200 |
| `cls_num_per_lane` | 56 | 18 |

#### [`UltrafastLaneDetector`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:52)

Main detector class.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, model_path, model_type=ModelType.TUSIMPLE, use_gpu=False)` | Initialize detector |
| `initialize_model` | `initialize_model(model_path, cfg, use_gpu)` (static) | Load model weights |
| `initialize_image_transform` | `initialize_image_transform()` (static) | Create transform pipeline |
| `detect_lanes` | `detect_lanes(self, image, draw_points=True, csv_path=None)` | Main detection method |
| `write_lanes` | `write_lanes(self, lane_lists, csv_path)` | Write lane data to CSV |
| `prepare_input` | `prepare_input(self, img)` | Preprocess image for inference |
| `inference` | `inference(self, input_tensor)` | Run model inference |
| `process_output` | `process_output(output, cfg)` (static) | Parse model output to lane points |
| `draw_lanes` | `draw_lanes(input_img, lanes_points, lanes_detected, cfg, draw_points, leftplotlist, rightplotlist)` (static) | Visualize detected lanes |

**detect_lanes() Flow:**
1. [`prepare_input()`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:188): Convert BGR to RGB, resize, normalize
2. [`inference()`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:200): Run forward pass
3. [`process_output()`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:206): Apply softmax, get lane coordinates
4. [`write_lanes()`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:129): Save to CSV
5. [`draw_lanes()`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:260): Create visualization

---

### 9. Custom Pipeline - [`custom_pipeline.py`](my_modules/custom_pipeline.py)

**Purpose:** Enhanced pipeline wrapper combining lane detection with 3D processing.

**Imports:**
```python
import sys
import os
from lateral_sota.ultrafastLaneDetector.ultrafastLaneDetector import UltrafastLaneDetector
from lateral_sota.ransacPlaneobject import ransacPlaneobject
```

**Classes:**

#### [`MyEnhancedPipeline`](my_modules/custom_pipeline.py:14)

Enhanced pipeline wrapper.

| Method | Signature | Purpose |
|--------|-----------|---------|
| `__init__` | `__init__(self, weights_path=None)` | Initialize with weights path |
| `run` | `run(self, image_path)` | Execute pipeline on image |

**Usage:**
```python
pipeline = MyEnhancedPipeline()
result = pipeline.run("path/to/image.png")
# Returns: {'lanes': lanes_image, 'image_path': image_path}
```

---

### 10. Infrastructure Files

#### [`download_weights.py`](scripts/download_weights.py)

**Purpose:** Download pretrained model weights.

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`download_with_gdown()`](scripts/download_weights.py:12) | `download_with_gdown(file_id, filename, subfolder)` | Download from Google Drive |
| [`download_with_curl()`](scripts/download_weights.py:43) | `download_with_curl(url, filename, subfolder)` | Download using curl |
| [`main()`](scripts/download_weights.py:73) | `main()` | Main download routine |

**Downloads:**
1. Lane Detection: TUSIMPLE ResNet-18 weights (Google Drive)
2. 3D Detection: PV-RCNN KITTI weights (OpenMMLab)

---

#### [`setup_dataset.py`](scripts/setup_dataset.py)

**Purpose:** Setup KITTI dataset via KaggleHub.

**Functions:**

| Function | Signature | Purpose |
|----------|-----------|---------|
| [`main()`](scripts/setup_dataset.py:13) | `main()` | Download and create symlink |

---

#### [`test_pipeline.py`](tests/test_pipeline.py)

**Purpose:** Unit tests for the pipeline.

**Test Classes:**

| Class | Tests |
|-------|-------|
| [`TestPipeline`](tests/test_pipeline.py:12) | Import tests, initialization tests |
| [`TestConfig`](tests/test_pipeline.py:34) | Configuration file existence |

---

#### [`default.yaml`](configs/default.yaml)

**Purpose:** Default configuration settings.

**Configuration Sections:**
```yaml
lane_detection:
  model_type: "TUSIMPLE"
  weights_path: "weights/lane_detection/tusimple_res18.pth"
  confidence_threshold: 0.5
  num_lanes: 4

detection_3d:
  enabled: false
  model: "pv_rcnn"
  weights_path: "weights/3d_detection/pv_rcnn_kitti.pth"

dataset:
  name: "kitti"
  path: "data/kitti"
  train_split: 0.8

output:
  save_dir: "outputs"
  save_visualizations: true
  save_detections: true
```

---

## Data Flow Diagram

### Complete Pipeline Data Flow

```mermaid
flowchart LR
    subgraph Input
        IMG[RGB Image]
        PCD[LiDAR PCD]
        CAL[Calibration]
        LBL[Object Labels]
    end
    
    subgraph Stage1[Stage 1: Lane Detection]
        ULF[UltrafastLaneDetector]
        CSV1[Lane CSV]
    end
    
    subgraph Stage2[Stage 2: 3D Matching]
        RANSAC[RANSAC Plane Seg]
        PROJ[LiDAR Projection]
        MATCH[Point Matching]
        FIT[RANSAC Fitting]
    end
    
    subgraph Stage3[Stage 3: Distance Calc]
        GEOM[Shapely Geometry]
        DIST[Distance Calculation]
        ROS[ROS Markers]
    end
    
    subgraph Stage4[Stage 4: Evaluation]
        EVAL[Evaluation Metrics]
        OUT[Output File]
    end
    
    IMG --> ULF --> CSV1
    PCD --> RANSAC --> PROJ --> MATCH
    CSV1 --> MATCH --> FIT
    CAL --> PROJ
    FIT --> GEOM --> DIST --> ROS
    LBL --> DIST
    DIST --> EVAL --> OUT
```

### Data File Flow

```
dataset/training/
    |-- image_2/{name}.png      --> 1_Lane_2D.py
    |-- velodyne/{name}.pcd     --> 2_*_Ransac_Matching.py
    |-- calib/{name}.txt        --> 2_*_Ransac_Matching.py
    |-- label_2/{name}.txt      --> 3_Marking.py, 4_Evaluation.py

CSV_Communication/
    |-- 1_lane.csv              <-- 1_Lane_2D.py --> 2_*_Ransac_Matching.py
    |-- 2_matched_left.txt      <-- 2_*_Ransac_Matching.py
    |-- 2_matched_right.txt     <-- 2_*_Ransac_Matching.py
    |-- left_lane_Ransac.txt    <-- 2_lineRansac_Matching.py --> 3_Marking.py
    |-- right_lane_Ransac.txt   <-- 2_lineRansac_Matching.py --> 3_Marking.py
    |-- evaluation.txt          <-- 4_Evaluation.py
```

---

## Configuration

### Model Configuration

The [`ModelConfig`](lateral_sota/ultrafastLaneDetector/ultrafastLaneDetector.py:28) class provides preset configurations:

| Parameter | TUSIMPLE | CULane |
|-----------|----------|--------|
| Image Width | 1242 | 1640 |
| Image Height | 375 | 590 |
| Griding Number | 100 | 200 |
| Classes Per Lane | 56 | 18 |
| Row Anchors | 56 values | 18 values |

### YAML Configuration

The [`configs/default.yaml`](configs/default.yaml) file provides runtime configuration:

- **Lane Detection:** Model type, weights path, thresholds
- **3D Detection:** Enable/disable, model selection
- **Dataset:** Path and split configuration
- **Output:** Save directories and flags

---

## Usage Examples

### Running Individual Pipeline Stages

```bash
# Stage 1: Lane Detection
cd src/lateral_sota
python 1_Lane_2D.py 7  # Process image 000007.png

# Stage 2a: Curved Road Matching
python 2_curveRansac_Matching.py 7

# Stage 2b: Straight Road Matching
python 2_lineRansac_Matching.py 7

# Stage 3: Distance Calculation (requires ROS)
python 3_Marking.py 7

# Stage 4: Evaluation
python 4_Evaluation.py 7
```

### Using the Detector in Code

```python
from lateral_sota.ultrafastLaneDetector.ultrafastLaneDetector import UltrafastLaneDetector, ModelType
import cv2

# Initialize detector
detector = UltrafastLaneDetector(
    model_path="weights/lane_detection/tusimple_res18.pth",
    model_type=ModelType.TUSIMPLE,
    use_gpu=False
)

# Detect lanes
image = cv2.imread("image.png")
result = detector.detect_lanes(image, draw_points=True, csv_path="output.csv")

# Display result
cv2.imshow("Lanes", result)
cv2.waitKey(0)
```

### Using the Enhanced Pipeline

```python
from my_modules.custom_pipeline import MyEnhancedPipeline

# Initialize
pipeline = MyEnhancedPipeline(weights_path="path/to/weights.pth")

# Run
result = pipeline.run("path/to/image.png")
print(result['lanes'])
```

### RANSAC Plane Segmentation

```python
from lateral_sota.ransacPlaneobject import ransacPlaneobject

# Segment point cloud
ground_points, object_points = ransacPlaneobject("path/to/pointcloud.pcd")

print(f"Ground points: {ground_points.shape}")
print(f"Object points: {object_points.shape}")
```

---

## Dependencies

### Core Dependencies
- `torch>=1.7.0` - Deep learning framework
- `torchvision>=0.8.0` - Vision models and transforms
- `numpy>=1.19.0` - Numerical computing
- `opencv-python>=4.5.0` - Image processing

### 3D & Geometry
- `open3d>=0.13.0` - Point cloud processing
- `shapely>=1.7.0` - Geometric operations
- `scipy>=1.5.0` - Scientific computing
- `scikit-learn>=0.24.0` - RANSAC and ML utilities
- `pcl` - Point Cloud Library (requires separate installation)

### Data & Visualization
- `kagglehub>=0.1.0` - Dataset downloading
- `pandas>=1.1.0` - Data manipulation
- `matplotlib>=3.3.0` - Plotting

### ROS (Optional)
- `rospy` - ROS Python bindings
- `sensor_msgs` - ROS message types
- `visualization_msgs` - RViz markers
- `geometry_msgs` - Geometry messages

### Development
- `jupyterlab` - Notebook environment
- `pytest` - Testing framework
- `black` - Code formatting
- `flake8` - Linting
- `gdown` - Google Drive downloads

---

## Notes

1. **ROS Dependency:** Modules [`3_Marking.py`](lateral_sota/3_Marking.py) and [`label_plotting.py`](lateral_sota/label_plotting.py) require ROS environment
2. **PCL Dependency:** [`ransacPlaneobject.py`](lateral_sota/ransacPlaneobject.py) requires PCL (Point Cloud Library) installation
3. **KITTI Dataset:** The pipeline expects KITTI dataset structure with specific directory layout
4. **CSV Communication:** Pipeline stages communicate via CSV files in `CSV_Communication/` directory
5. **Real-time Version:** A real-time version is available at: https://github.com/ChicagoPark/Lateral_Realtime

---

## References

- **IEEE Conference Publication:** https://github.com/ChicagoPark/Lateral
- **Real-time Version:** https://github.com/ChicagoPark/Lateral_Realtime
- **Ultra-Fast Lane Detection:** https://github.com/cfzd/Ultra-Fast-Lane-Detection
- **KITTI Dataset:** http://www.cvlibs.net/datasets/kitti/

---

